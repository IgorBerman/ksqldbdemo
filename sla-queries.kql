-- run this from
-- docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
-- set 'commit.interval.ms'='2000';
-- set 'cache.max.bytes.buffering'='10000000';
-- set 'auto.offset.reset'='earliest';


-- raw stream
CREATE STREAM raw_sla_reports_stream (msgId VARCHAR, sourceLabels map<VARCHAR,VARCHAR>, data array<struct<logicalTime BIGINT, processingTime BIGINT, labels map<VARCHAR,VARCHAR>, value INT>> ) 
with (kafka_topic = 'raw_sla_reports', value_format = 'json', partitions=1, REPLICAS = 1);


-- exploded data(i.e. every type in separate line)
CREATE STREAM raw_sla_reports_exploded_stream  WITH ( partitions = 1, REPLICAS = 1) AS
    SELECT msgId, sourceLabels, EXPLODE(data) as data FROM raw_sla_reports_stream;


-- preparing for report
CREATE STREAM raw_sla_reports_exploded_projected_stream WITH ( TIMESTAMP='LOGICALTIME', partitions = 1, REPLICAS = 1) AS
	select 
		MSGID, 
		SOURCELABELS['sourceGroup'] as sourceGroup, 
		DATA->LOGICALTIME as LOGICALTIME, 
		DATA->processingTime as processingTime,
		DATA->processingTime - DATA->LOGICALTIME as delay,
		data->value as value, 
		data->labels['msgtype'] as msgtype 
	from raw_sla_reports_exploded_stream EMIT CHANGES
	 ;


-- report with delays bucketing and 1m window
CREATE table delays_per_group_histo_table WITH ( partitions = 1, REPLICAS = 1) AS 
	SELECT 
			sourcegroup+'_'+msgtype+'_'+TIMESTAMPTOSTRING(WindowStart(), 'yyyy-MM-dd-HH-mm') as aggKey,
			sourceGroup, 
			msgtype, 
			WindowStart() AS window_start, 
			sum(CASE WHEN delay <= 60*1000 THEN value else 0 END) as zero_to_one_min, 
			sum(CASE WHEN delay >  60*1000 and delay <= 5*60*1000 THEN value else 0 END) as one_to_five_mins,
			sum(CASE WHEN delay >  5*60*1000 and delay <= 10*60*1000 THEN value else 0 END) as five_to_ten_mins,   
			sum(CASE WHEN delay > 10*60*1000 and delay <= 30*60*1000 THEN value else 0 END) as ten_to_thirty_mins,  
			sum(CASE WHEN delay >  30*60*1000 THEN value else 0 END) as more_than_thirty_mins,  
			sum(value) AS total_protos 
		FROM raw_sla_reports_exploded_projected_stream 
			window TUMBLING (size 60 second) 
	GROUP BY sourceGroup, msgtype;

-- print DELAYS_PER_GROUP_HISTO_TABLE;


-- select *, TIMESTAMPTOSTRING(window_start, 'yyyy-MM-dd HH:mm:ss.SSS') as window_start_str from delays_per_group_histo_table emit changes;

-- select * from raw_sla_reports_exploded_projected_stream;

-- select * from delays_per_group_histo_table where ROWKEY='trc|+|ProtoUserEvent' and windowstart=1576059000000;

-- console producer: docker exec -it broker kafka-console-producer --broker-list :9092 --topic raw_sla_reports
-- console consumer: docker exec -it broker kafka-console-consumer --bootstrap-server 0.0.0.0:9092 --topic raw_sla_reports


-- http://localhost:8088/status
-- http://localhost:8088/healthcheck

